{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_gene_names():\n",
    "    ret = set()\n",
    "    syns = {}\n",
    "\n",
    "    with open('genenames.txt') as f:\n",
    "        c = 0\n",
    "        for l in f:\n",
    "            c += 1\n",
    "            if c == 1:\n",
    "                header = l.split('\\t')\n",
    "                syn_index = header.index('Synonyms')\n",
    "                symb_index = header.index('Previous Symbols')\n",
    "                continue\n",
    "                \n",
    "            ls = l.split('\\t')\n",
    "            gene = ls[1]\n",
    "            ret.add(gene)\n",
    "            this_syn = [x.strip() for x in ls[syn_index].split(',')]\n",
    "            for x in this_syn:\n",
    "                syns[x] = gene\n",
    "            \n",
    "            symbols = [x.strip() for x in ls[symb_index].split(',')]\n",
    "            for x in symbols:\n",
    "                syns[x] = gene\n",
    "            \n",
    "            \n",
    "    return {x: None for x in ret}, syns\n",
    "\n",
    "stop = {\n",
    "    '2': None,\n",
    "    'T': None,\n",
    "    'B': None,\n",
    "}\n",
    "\n",
    "def check_gene_name(x):\n",
    "    \n",
    "    if x in stop:\n",
    "        return None\n",
    "    \n",
    "    if x in genenames:\n",
    "        if not 'realnames' in stats:\n",
    "            stats['realnames'] = 0\n",
    "        stats['realnames'] += 1\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    if x in genesyns:\n",
    "        \n",
    "        if not 'syns' in stats:\n",
    "            stats['syns'] = 0\n",
    "        stats['syns'] += 1\n",
    "        \n",
    "        return genesyns[x]\n",
    "    \n",
    "    extra_synonyms = {\n",
    "        # Found : Real\n",
    "        'FXII': 'F12',\n",
    "    }\n",
    "    \n",
    "    if x in extra_synonyms:\n",
    "        return extra_synonyms[x]\n",
    "    \n",
    "    if x.lower() in ['mitochondrial', 'mtdna']:\n",
    "        \n",
    "        if not 'mitochondrial' in stats:\n",
    "            stats['mitochondrial'] = 0\n",
    "        stats['mitochondrial'] += 1\n",
    "        \n",
    "        return 'mtdna'\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genenames, genesyns = load_gene_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genenames['BRCA2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'HPRT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-511b85dce355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenesyns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HPRT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'HPRT'"
     ]
    }
   ],
   "source": [
    "genesyns['HPRT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record: 1\n",
      "Record: 2\n",
      "Record: 3\n",
      "Record: 4\n",
      "Record: 5\n",
      "Record: 6\n",
      "Record: 7\n",
      "Record: 8\n",
      "Record: 9\n",
      "Record: 10\n",
      "Record: 11\n",
      "Record: 12\n",
      "Record: 13\n",
      "Record: 14\n",
      "Record: 15\n",
      "Record: 16\n",
      "Record: 17\n",
      "Record: 18\n",
      "Record: 19\n",
      "Record: 20\n",
      "Record: 21\n",
      "Record: 22\n",
      "Record: 23\n",
      "Record: 24\n",
      "Record: 25\n",
      "Record: 26\n",
      "Record: 27\n",
      "Record: 28\n",
      "Record: 29\n",
      "Record: 30\n",
      "Record: 31\n",
      "Record: 32\n",
      "Record: 33\n",
      "Record: 34\n",
      "Record: 35\n",
      "Record: 36\n",
      "Record: 37\n",
      "Record: 38\n",
      "Record: 39\n",
      "Record: 40\n",
      "Record: 41\n",
      "Record: 42\n",
      "Record: 43\n",
      "Record: 44\n",
      "Record: 45\n",
      "Record: 46\n",
      "Record: 47\n",
      "Record: 48\n",
      "Record: 49\n",
      "Record: 50\n",
      "Record: 51\n",
      "Record: 52\n",
      "Record: 53\n",
      "Record: 54\n",
      "Record: 55\n",
      "Record: 56\n",
      "Record: 57\n",
      "Record: 58\n",
      "Record: 59\n",
      "Record: 60\n",
      "Record: 61\n",
      "Record: 62\n",
      "Record: 63\n",
      "Record: 64\n",
      "Record: 65\n",
      "Record: 66\n",
      "Record: 67\n",
      "('Abstract counter:', 100)\n",
      "Record: 68\n",
      "Record: 69\n",
      "Record: 70\n",
      "Record: 71\n",
      "Record: 72\n",
      "Record: 73\n",
      "Record: 74\n",
      "Record: 75\n",
      "Record: 76\n",
      "Record: 77\n",
      "Record: 78\n",
      "Record: 79\n",
      "Record: 80\n",
      "Record: 81\n",
      "Record: 82\n",
      "Record: 83\n",
      "Record: 84\n",
      "Record: 85\n",
      "Record: 86\n",
      "Record: 87\n",
      "Record: 88\n",
      "Record: 89\n",
      "Record: 90\n",
      "Record: 91\n",
      "Record: 92\n",
      "Record: 93\n",
      "Record: 94\n",
      "Record: 95\n",
      "Record: 96\n",
      "Record: 97\n",
      "Record: 98\n",
      "Record: 99\n",
      "('Abstract counter:', 200)\n",
      "('HGVS FOUND:', 100)\n",
      "Record: 100\n",
      "Generated: parsed_abstracts.json\n",
      "Generated: stats.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "stats = {}\n",
    "\n",
    "def gen_abstracts(filename, per=100):\n",
    "    abstract_counter = 0\n",
    "    hgvs_counter = 0\n",
    "    with open(filename) as f:\n",
    "        for l in f:\n",
    "                        \n",
    "            data = json.loads(l)\n",
    "            for result in data['resultList']['result']:\n",
    "                \n",
    "                if not 'pubmedcounter' in stats:\n",
    "                    stats['pubmedcounter'] = 0\n",
    "                stats['pubmedcounter'] += 1\n",
    "                \n",
    "                if 'abstractText'in result:\n",
    "                    abstract = result['abstractText']\n",
    "                    abstract_counter += 1\n",
    "                    if abstract_counter % per == 0:\n",
    "                        print ('Abstract counter:', abstract_counter)\n",
    "                        \n",
    "                    if not 'abstractcounter' in stats:\n",
    "                        stats['abstractcounter'] = 0\n",
    "                    stats['abstractcounter'] += 1\n",
    "                        \n",
    "                    #if 'NM_' in abstract:\n",
    "                    #    print (abstract)\n",
    "                    #    assert False\n",
    "                    yield abstract\n",
    "                else:\n",
    "                    if not 'noabstract' in stats:\n",
    "                        stats['noabstract'] = 0\n",
    "                    stats['noabstract'] += 1\n",
    "\n",
    "def gen_hgvs(filename):\n",
    "    hgvs_counter = 0\n",
    "    \n",
    "    for abstract in gen_abstracts(filename):\n",
    "        \n",
    "        transcripts = get_transcripts(abstract)\n",
    "        \n",
    "        for hgvs in gen_hgvs_2(abstract):\n",
    "            hgvs_counter += 1\n",
    "\n",
    "            if hgvs_counter % 100 == 0:\n",
    "                print ('HGVS FOUND:', hgvs_counter)\n",
    "            \n",
    "            gene = get_gene_names(abstract, hgvs[1])\n",
    "            \n",
    "            yield abstract, gene, ''.join(hgvs), transcripts\n",
    "\n",
    "def get_gene_names(abstract, hgvs):\n",
    "    pos = abstract.index(hgvs)\n",
    "    \n",
    "    before = abstract[:pos]\n",
    "    after = abstract[pos+len(hgvs):]\n",
    "    \n",
    "    #Check before\n",
    "    before = before.split()[::-1]\n",
    "    before = [noparenthesis(x) for x in before]\n",
    "    \n",
    "    for word in before:\n",
    "        name = check_gene_name(word)\n",
    "        if name:\n",
    "            return name\n",
    "    \n",
    "    #Check after\n",
    "    after = [noparenthesis(x) for x in after.split()]\n",
    "    for word in after:\n",
    "        name = check_gene_name(word)\n",
    "        if name:\n",
    "            return name\n",
    "    \n",
    "    if not 'no_gene' in stats:\n",
    "        stats['no_gene'] = 0\n",
    "        \n",
    "    stats['no_gene'] += 1\n",
    "    \n",
    "    #print abstract\n",
    "    #print hgvs\n",
    "    \n",
    "    #if stats['no_gene'] > 1:\n",
    "    #    assert False\n",
    "    return None\n",
    "\n",
    "def gen_hgvs_2(abstract):\n",
    "    #245 A>\n",
    "    #found = re.findall(r'(.{1,100})([\\d]+[\\s]*[ACGT]+[\\s]*>)(.{1,100})',abstract, re.UNICODE)\n",
    "    found = re.findall(r'[\\d]+[\\s]*[ACGT]+[\\s]*>',abstract, re.UNICODE)\n",
    "    \n",
    "    if not found:\n",
    "        if not 'nohgvs' in stats:\n",
    "            stats['nohgvs'] = 0\n",
    "        stats['nohgvs'] += 1\n",
    "    \n",
    "    for f in found:\n",
    "        start = abstract.index(f)\n",
    "        before = abstract[:start]\n",
    "        after = abstract[start+len(f):]\n",
    "        \n",
    "        # We do not want any HGVS before and after the one that we found\n",
    "        before = before.replace('>','')\n",
    "        after = after.replace('>', '')\n",
    "\n",
    "        yield before, f, after\n",
    "    \n",
    "\n",
    "def get_transcripts(text):\n",
    "    return re.findall(r'[A-Z][A-Z]_[\\d]{4,15}\\.?[\\d]*', text, re.UNICODE)\n",
    "        \n",
    "def nowhite(p):\n",
    "    return re.sub(r'[\\s]', '', p, flags=re.UNICODE)\n",
    "\n",
    "def noparenthesis(p):\n",
    "    return re.sub(r'[\\(\\),\\.\\:]', '', p, flags=re.UNICODE)\n",
    "\n",
    "def post_process(hgvs):\n",
    "\n",
    "    s = None\n",
    "    \n",
    "    if not s:\n",
    "        # c.6348+1G>A\n",
    "        s = re.search(r'[CcGgpP][\\s]*\\.[\\s]*[\\d]+[\\s]*[\\+\\-][\\s]*[\\d]+[\\s]*[ACGT]+[\\s]*>[\\s]*[ACGT]+', hgvs, re.UNICODE)\n",
    "    \n",
    "    if not s:\n",
    "        # c.969C > A\n",
    "        s = re.search(r'[CcGgpPm][\\s]*\\.[\\s]*[\\d]+[\\s]*[ACGT][\\s]*>[\\s]*[ACGTS]+', hgvs, re.UNICODE)\n",
    "    \n",
    "    if not s:\n",
    "        # 236G > A\n",
    "        s = re.search(r'[\\d]+[\\s]*[ACGT]+[\\s]*>[\\s]*[ACGT]+', hgvs, re.UNICODE)\n",
    "    \n",
    "    if not s:\n",
    "        # c.743C > del \n",
    "        s = re.search(r'[cCgGpP]\\.[\\d]+[ACGT]+[\\s]*>[\\s]*del', hgvs, re.UNICODE)\n",
    "    \n",
    "    #print ('=====')\n",
    "    if s:\n",
    "        result = nowhite(s.group(0))\n",
    "        #print (hgvs)\n",
    "        #print (result)\n",
    "        return result\n",
    "    else:\n",
    "        #print (hgvs)\n",
    "        #assert False\n",
    "        \n",
    "        if not 'noparsehgvs' in stats:\n",
    "            stats['noparsehgvs'] = 0\n",
    "        stats['noparsehgvs'] += 1\n",
    "        \n",
    "        return None\n",
    "        \n",
    "        \n",
    "def do_1():\n",
    "    output_fn = 'parsed_abstracts.json'\n",
    "    output_f = codecs.open(output_fn, 'w', 'utf-8')\n",
    "    records = 0\n",
    "    for abstract, gene, hgvs, transcripts in gen_hgvs('abstracts.json'):\n",
    "        hgvs = post_process(hgvs)\n",
    "        if hgvs is None:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        records += 1\n",
    "        \n",
    "        #if records <8:\n",
    "        #    continue\n",
    "        \n",
    "        if records > 100:\n",
    "            break\n",
    "        \n",
    "        to_save = {\n",
    "            'abstract': abstract,\n",
    "            'gene': gene,\n",
    "            'hgvs': hgvs,\n",
    "            'transcripts': transcripts,\n",
    "            'record': records\n",
    "        }\n",
    "        \n",
    "        #print gene, hgvs, transcripts\n",
    "        if False:\n",
    "            output_f.write('=========== {} ================\\n'.format(records))\n",
    "            output_f.write(abstract + '\\n')\n",
    "            output_f.write('GENE:' + gene + '\\n')\n",
    "            output_f.write('HGVS:'+ hgvs + '\\n')\n",
    "            output_f.write('Transcripts:' + str(transcripts) + '\\n')\n",
    "        if True:\n",
    "            print 'Record:', records\n",
    "            json.dump(to_save, output_f)\n",
    "            output_f.write('\\n')\n",
    "            output_f.flush()\n",
    "               \n",
    "    output_f.close()\n",
    "    print 'Generated:', output_fn\n",
    "    \n",
    "    with open('stats.json', 'w') as f:\n",
    "        json.dump(stats, f)\n",
    "    print 'Generated:', 'stats.json'\n",
    "\n",
    "def do_2():\n",
    "    counter={}\n",
    "    for abstract in gen_abstracts('abstracts.json', per=10000):\n",
    "        for tr in ['NT_', 'NG_', 'NC_']:\n",
    "            if tr in abstract:\n",
    "                #print '=====  {}  ======'.format(tr)\n",
    "                if not tr in counter:\n",
    "                    counter[tr] = []\n",
    "                    \n",
    "                counter[tr].append(abstract)\n",
    "                #print abstract\n",
    "                #assert False\n",
    "                \n",
    "    #print (counter)\n",
    "    return counter\n",
    "        \n",
    "do_1()\n",
    "#do_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\ttranscript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\r\n",
      "SERPINF1:c.1067\tCCDS11012 (protein_coding)\tSERPINF1\t+\tchr17:g.1680550T/c.1067T/.\tinside_[cds_in_exon_7]\tsource=CCDS\r\n"
     ]
    }
   ],
   "source": [
    "!/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i 'SERPINF1:c.1067' --refversion hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LIS1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-6a6307ca66fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LIS1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'LIS1'"
     ]
    }
   ],
   "source": [
    "genenames['LIS1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Abstract counter:', 10000)\n",
      "('Abstract counter:', 20000)\n",
      "('Abstract counter:', 30000)\n",
      "('Abstract counter:', 40000)\n",
      "('Abstract counter:', 50000)\n",
      "('Abstract counter:', 60000)\n",
      "('Abstract counter:', 70000)\n",
      "('Abstract counter:', 80000)\n",
      "('Abstract counter:', 90000)\n",
      "('Abstract counter:', 100000)\n",
      "('Abstract counter:', 110000)\n",
      "('Abstract counter:', 120000)\n",
      "('Abstract counter:', 130000)\n",
      "('Abstract counter:', 140000)\n",
      "('Abstract counter:', 150000)\n",
      "('Abstract counter:', 160000)\n",
      "('Abstract counter:', 170000)\n",
      "('Abstract counter:', 180000)\n",
      "('Abstract counter:', 190000)\n",
      "('Abstract counter:', 200000)\n",
      "('Abstract counter:', 210000)\n",
      "('Abstract counter:', 220000)\n",
      "('Abstract counter:', 230000)\n",
      "('Abstract counter:', 240000)\n",
      "('Abstract counter:', 250000)\n",
      "('Abstract counter:', 260000)\n",
      "('Abstract counter:', 270000)\n",
      "('Abstract counter:', 280000)\n",
      "('Abstract counter:', 290000)\n",
      "('Abstract counter:', 300000)\n",
      "('Abstract counter:', 310000)\n",
      "('Abstract counter:', 320000)\n",
      "('Abstract counter:', 330000)\n",
      "('Abstract counter:', 340000)\n",
      "('Abstract counter:', 350000)\n",
      "('Abstract counter:', 360000)\n",
      "('Abstract counter:', 370000)\n",
      "('Abstract counter:', 380000)\n",
      "('Abstract counter:', 390000)\n",
      "('Abstract counter:', 400000)\n",
      "('Abstract counter:', 410000)\n",
      "('Abstract counter:', 420000)\n",
      "('Abstract counter:', 430000)\n",
      "('Abstract counter:', 440000)\n",
      "('Abstract counter:', 450000)\n",
      "('Abstract counter:', 460000)\n",
      "('Abstract counter:', 470000)\n",
      "('Abstract counter:', 480000)\n",
      "('Abstract counter:', 490000)\n",
      "('Abstract counter:', 500000)\n",
      "('Abstract counter:', 510000)\n",
      "('Abstract counter:', 520000)\n",
      "('Abstract counter:', 530000)\n",
      "('Abstract counter:', 540000)\n",
      "('Abstract counter:', 550000)\n",
      "('Abstract counter:', 560000)\n",
      "('Abstract counter:', 570000)\n",
      "('Abstract counter:', 580000)\n",
      "('Abstract counter:', 590000)\n",
      "('Abstract counter:', 600000)\n",
      "('Abstract counter:', 610000)\n",
      "('Abstract counter:', 620000)\n",
      "('Abstract counter:', 630000)\n",
      "('Abstract counter:', 640000)\n",
      "('Abstract counter:', 650000)\n",
      "('Abstract counter:', 660000)\n",
      "('Abstract counter:', 670000)\n",
      "('Abstract counter:', 680000)\n",
      "('Abstract counter:', 690000)\n",
      "('Abstract counter:', 700000)\n",
      "('Abstract counter:', 710000)\n",
      "('Abstract counter:', 720000)\n",
      "('Abstract counter:', 730000)\n",
      "('Abstract counter:', 740000)\n",
      "('Abstract counter:', 750000)\n",
      "('Abstract counter:', 760000)\n",
      "('Abstract counter:', 770000)\n",
      "('Abstract counter:', 780000)\n",
      "('Abstract counter:', 790000)\n",
      "('Abstract counter:', 800000)\n",
      "('Abstract counter:', 810000)\n",
      "('Abstract counter:', 820000)\n",
      "('Abstract counter:', 830000)\n",
      "('Abstract counter:', 840000)\n",
      "('Abstract counter:', 850000)\n",
      "('Abstract counter:', 860000)\n",
      "('Abstract counter:', 870000)\n",
      "('Abstract counter:', 880000)\n",
      "('Abstract counter:', 890000)\n",
      "('Abstract counter:', 900000)\n",
      "('Abstract counter:', 910000)\n"
     ]
    }
   ],
   "source": [
    "counter = do_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nt_ng_abstracts.json', 'w') as f:\n",
    "    json.dump(counter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NG_ 52\n",
      "NT_ 24\n",
      "NC_ 68\n"
     ]
    }
   ],
   "source": [
    "for x,y in counter.iteritems():\n",
    "    print x, len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mutationinfo/localpython/lib/python2.7/site-packages/psycopg2-2.7.4-py2.7-linux-x86_64.egg/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "from MutationInfo import MutationInfo as MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING dbfile.open_index: Falling back to hash index: unable to import bsddb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pygr-log:Falling back to hash index: unable to import bsddb\n"
     ]
    }
   ],
   "source": [
    "mi = MI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN_1\n",
    "* Run with:  ```/home/user/mutationinfo/localpython/bin/python run_1.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run_1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_1.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "def load_gene_names():\n",
    "    ret = set()\n",
    "    syns = {}\n",
    "\n",
    "    with open('genenames.txt') as f:\n",
    "        c = 0\n",
    "        for l in f:\n",
    "            c += 1\n",
    "            if c == 1:\n",
    "                header = l.split('\\t')\n",
    "                syn_index = header.index('Synonyms')\n",
    "                symb_index = header.index('Previous Symbols')\n",
    "                continue\n",
    "                \n",
    "            ls = l.split('\\t')\n",
    "            gene = ls[1]\n",
    "            ret.add(gene)\n",
    "            this_syn = [x.strip() for x in ls[syn_index].split(',')]\n",
    "            for x in this_syn:\n",
    "                syns[x] = gene\n",
    "            \n",
    "            symbols = [x.strip() for x in ls[symb_index].split(',')]\n",
    "            for x in symbols:\n",
    "                syns[x] = gene\n",
    "            \n",
    "            \n",
    "    return {x: None for x in ret}, syns\n",
    "\n",
    "stop = {\n",
    "    '2': None,\n",
    "    'T': None,\n",
    "    'B': None,\n",
    "}\n",
    "\n",
    "def check_gene_name(x):\n",
    "    \n",
    "    if x in stop:\n",
    "        return None\n",
    "    \n",
    "    if x in genenames:\n",
    "        if not 'realnames' in stats:\n",
    "            stats['realnames'] = 0\n",
    "        stats['realnames'] += 1\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    if x in genesyns:\n",
    "        \n",
    "        if not 'syns' in stats:\n",
    "            stats['syns'] = 0\n",
    "        stats['syns'] += 1\n",
    "        \n",
    "        return genesyns[x]\n",
    "    \n",
    "    extra_synonyms = {\n",
    "        # Found : Real\n",
    "        'FXII': 'F12',\n",
    "    }\n",
    "    \n",
    "    if x in extra_synonyms:\n",
    "        return extra_synonyms[x]\n",
    "    \n",
    "    if x.lower() in ['mitochondrial', 'mtdna']:\n",
    "        \n",
    "        if not 'mitochondrial' in stats:\n",
    "            stats['mitochondrial'] = 0\n",
    "        stats['mitochondrial'] += 1\n",
    "        \n",
    "        return 'mtdna'\n",
    "    \n",
    "    return None\n",
    "\n",
    "###################################\n",
    "genenames, genesyns = load_gene_names()\n",
    "\n",
    "import re\n",
    "import gzip\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "stats = {}\n",
    "\n",
    "def gen_abstracts(filename, per=100):\n",
    "    abstract_counter = 0\n",
    "    hgvs_counter = 0\n",
    "    with gzip.open(filename, 'rt') as f:\n",
    "        for l in f:\n",
    "                        \n",
    "            data = json.loads(l)\n",
    "            for result in data['resultList']['result']:\n",
    "                \n",
    "                if not 'pubmedcounter' in stats:\n",
    "                    stats['pubmedcounter'] = 0\n",
    "                stats['pubmedcounter'] += 1\n",
    "                \n",
    "                if 'abstractText'in result:\n",
    "                    abstract = result['abstractText']\n",
    "                    abstract_counter += 1\n",
    "                    if abstract_counter % per == 0:\n",
    "                        print ('Abstract counter:', abstract_counter)\n",
    "                        \n",
    "                    if not 'abstractcounter' in stats:\n",
    "                        stats['abstractcounter'] = 0\n",
    "                    stats['abstractcounter'] += 1\n",
    "                        \n",
    "                    #if 'NM_' in abstract:\n",
    "                    #    print (abstract)\n",
    "                    #    assert False\n",
    "                    yield abstract\n",
    "                else:\n",
    "                    if not 'noabstract' in stats:\n",
    "                        stats['noabstract'] = 0\n",
    "                    stats['noabstract'] += 1\n",
    "\n",
    "def gen_hgvs(filename):\n",
    "    hgvs_counter = 0\n",
    "    \n",
    "    for abstract in gen_abstracts(filename):\n",
    "        \n",
    "        transcripts = get_transcripts(abstract)\n",
    "        \n",
    "        for hgvs in gen_hgvs_2(abstract):\n",
    "            hgvs_counter += 1\n",
    "\n",
    "            if hgvs_counter % 100 == 0:\n",
    "                print ('HGVS FOUND:', hgvs_counter)\n",
    "            \n",
    "            gene = get_gene_names(abstract, hgvs[1])\n",
    "            \n",
    "            yield abstract, gene, ''.join(hgvs), transcripts\n",
    "\n",
    "def get_gene_names(abstract, hgvs):\n",
    "    pos = abstract.index(hgvs)\n",
    "    \n",
    "    before = abstract[:pos]\n",
    "    after = abstract[pos+len(hgvs):]\n",
    "    \n",
    "    #Check before\n",
    "    before = before.split()[::-1]\n",
    "    before = [noparenthesis(x) for x in before]\n",
    "    \n",
    "    for word in before:\n",
    "        name = check_gene_name(word)\n",
    "        if name:\n",
    "            return name\n",
    "    \n",
    "    #Check after\n",
    "    after = [noparenthesis(x) for x in after.split()]\n",
    "    for word in after:\n",
    "        name = check_gene_name(word)\n",
    "        if name:\n",
    "            return name\n",
    "    \n",
    "    if not 'no_gene' in stats:\n",
    "        stats['no_gene'] = 0\n",
    "        \n",
    "    stats['no_gene'] += 1\n",
    "    \n",
    "    #print abstract\n",
    "    #print hgvs\n",
    "    \n",
    "    #if stats['no_gene'] > 1:\n",
    "    #    assert False\n",
    "    return None\n",
    "\n",
    "def gen_hgvs_2(abstract):\n",
    "    #245 A>\n",
    "    #found = re.findall(r'(.{1,100})([\\d]+[\\s]*[ACGT]+[\\s]*>)(.{1,100})',abstract, re.UNICODE)\n",
    "    found = re.findall(r'[\\d]+[\\s]*[ACGT]+[\\s]*>',abstract, re.UNICODE)\n",
    "    \n",
    "    if not found:\n",
    "        if not 'nohgvs' in stats:\n",
    "            stats['nohgvs'] = 0\n",
    "        stats['nohgvs'] += 1\n",
    "    \n",
    "    for f in found:\n",
    "        start = abstract.index(f)\n",
    "        before = abstract[:start]\n",
    "        after = abstract[start+len(f):]\n",
    "        \n",
    "        # We do not want any HGVS before and after the one that we found\n",
    "        before = before.replace('>','')\n",
    "        after = after.replace('>', '')\n",
    "\n",
    "        yield before, f, after\n",
    "    \n",
    "\n",
    "def get_transcripts(text):\n",
    "    return re.findall(r'[A-Z][A-Z]_[\\d]{4,15}\\.?[\\d]*', text, re.UNICODE)\n",
    "        \n",
    "def nowhite(p):\n",
    "    return re.sub(r'[\\s]', '', p, flags=re.UNICODE)\n",
    "\n",
    "def noparenthesis(p):\n",
    "    return re.sub(r'[\\(\\),\\.\\:]', '', p, flags=re.UNICODE)\n",
    "\n",
    "def post_process(hgvs):\n",
    "\n",
    "    s = None\n",
    "    \n",
    "    if not s:\n",
    "        # c.6348+1G>A\n",
    "        s = re.search(r'[CcGgpP][\\s]*\\.[\\s]*[\\d]+[\\s]*[\\+\\-][\\s]*[\\d]+[\\s]*[ACGT]+[\\s]*>[\\s]*[ACGT]+', hgvs, re.UNICODE)\n",
    "    \n",
    "    if not s:\n",
    "        # c.969C > A\n",
    "        s = re.search(r'[CcGgpPm][\\s]*\\.[\\s]*[\\d]+[\\s]*[ACGT][\\s]*>[\\s]*[ACGTS]+', hgvs, re.UNICODE)\n",
    "    \n",
    "    if not s:\n",
    "        # 236G > A\n",
    "        s = re.search(r'[\\d]+[\\s]*[ACGT]+[\\s]*>[\\s]*[ACGT]+', hgvs, re.UNICODE)\n",
    "    \n",
    "    if not s:\n",
    "        # c.743C > del \n",
    "        s = re.search(r'[cCgGpP]\\.[\\d]+[ACGT]+[\\s]*>[\\s]*del', hgvs, re.UNICODE)\n",
    "    \n",
    "    #print ('=====')\n",
    "    if s:\n",
    "        result = nowhite(s.group(0))\n",
    "        #print (hgvs)\n",
    "        #print (result)\n",
    "        return result\n",
    "    else:\n",
    "        #print (hgvs)\n",
    "        #assert False\n",
    "        \n",
    "        if not 'noparsehgvs' in stats:\n",
    "            stats['noparsehgvs'] = 0\n",
    "        stats['noparsehgvs'] += 1\n",
    "        \n",
    "        return None\n",
    "        \n",
    "        \n",
    "def do_1():\n",
    "    output_fn = 'parsed_abstracts.json'\n",
    "    output_f = codecs.open(output_fn, 'w', 'utf-8')\n",
    "    records = 0\n",
    "    for abstract, gene, hgvs, transcripts in gen_hgvs('abstracts.json.gz'):\n",
    "        hgvs = post_process(hgvs)\n",
    "        if hgvs is None:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        records += 1\n",
    "        if records % 100 == 0:\n",
    "            print 'Records:', records\n",
    "        \n",
    "        #if records <8:\n",
    "        #    continue\n",
    "        \n",
    "        #if records > 100:\n",
    "        #    break\n",
    "        \n",
    "        to_save = {\n",
    "            'abstract': abstract,\n",
    "            'gene': gene,\n",
    "            'hgvs': hgvs,\n",
    "            'transcripts': transcripts,\n",
    "            'record': records\n",
    "        }\n",
    "        \n",
    "        #print gene, hgvs, transcripts\n",
    "        if False:\n",
    "            output_f.write('=========== {} ================\\n'.format(records))\n",
    "            output_f.write(abstract + '\\n')\n",
    "            output_f.write('GENE:' + gene + '\\n')\n",
    "            output_f.write('HGVS:'+ hgvs + '\\n')\n",
    "            output_f.write('Transcripts:' + str(transcripts) + '\\n')\n",
    "        if True:\n",
    "            json.dump(to_save, output_f)\n",
    "            output_f.write('\\n')\n",
    "            output_f.flush()\n",
    "               \n",
    "    output_f.close()\n",
    "    print 'Generated:', output_fn\n",
    "    \n",
    "    with open('stats.json', 'w') as f:\n",
    "        json.dump(stats, f)\n",
    "    print 'Generated:', 'stats.json'\n",
    "\n",
    "def do_2():\n",
    "    counter={}\n",
    "    for abstract in gen_abstracts('abstracts.json.gz', per=10000):\n",
    "        for tr in ['NT_', 'NG_', 'NC_']:\n",
    "            if tr in abstract:\n",
    "                #print '=====  {}  ======'.format(tr)\n",
    "                if not tr in counter:\n",
    "                    counter[tr] = []\n",
    "                    \n",
    "                counter[tr].append(abstract)\n",
    "                #print abstract\n",
    "                #assert False\n",
    "                \n",
    "    #print (counter)\n",
    "    return counter\n",
    "        \n",
    "do_1()\n",
    "#do_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN_2\n",
    "\n",
    "* Run with ```/home/user/mutationinfo/localpython/bin/python run_2.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run_2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_2.py\n",
    "\n",
    "#assert False # THIS IS ON PURPOSE. DO NOT RUN THIS\n",
    "\n",
    "import re\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "from StringIO import StringIO\n",
    "\n",
    "def execute(command):\n",
    "    process = subprocess.Popen(command, shell=True,\n",
    "                           stdout=subprocess.PIPE, \n",
    "                           stderr=subprocess.PIPE)\n",
    "\n",
    "    # wait for the process to terminate\n",
    "    out, err = process.communicate()\n",
    "    errcode = process.returncode\n",
    "    \n",
    "    out = out.decode('utf-8')\n",
    "    err = err.decode('utf-8')\n",
    "    \n",
    "    #print ('STDOUT:')\n",
    "    #print (out)\n",
    "    #print ('ERR:')\n",
    "    #print (err)\n",
    "    #print ('RETURN CODE:', errcode)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def inverse(s):\n",
    "    \n",
    "    return {\n",
    "        'A': 'T',\n",
    "        'T': 'A',\n",
    "        'C': 'G',\n",
    "        'G': 'C',\n",
    "    }[s]\n",
    "\n",
    "stats_2 = {}\n",
    "\n",
    "def get_transvar_reference(coord, strand):\n",
    "    s = re.search(r'chr[\\dXY]+:g.[\\d]+([ACGT]+)/', coord)\n",
    "    if s:\n",
    "        reference = s.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    if strand == '-':\n",
    "        return inverse(reference)\n",
    "    elif strand == '+':\n",
    "        return reference\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "\n",
    "def parse_transvar_output(output,command=None, hgvs=None, abstract=None):\n",
    "    ls = output.split('\\n')\n",
    "    ls = [x.split('\\t') for x in ls if x.strip()] \n",
    "    strand_i = ls[0].index('strand')\n",
    "    coord_i = ls[0].index('coordinates(gDNA/cDNA/protein)')\n",
    "    transcript_i = ls[0].index('transcript')\n",
    "    \n",
    "    ret = {l[transcript_i]:get_transvar_reference(l[coord_i], l[strand_i])  for l in ls[1:]}\n",
    "    return ret    \n",
    "\n",
    "def load_parsed_abstracts():\n",
    "    with open('parsed_abstracts.json') as f:\n",
    "        for l in f:\n",
    "            data = json.loads(l)\n",
    "            yield data\n",
    "            \n",
    "def apply_transvar():\n",
    "    \n",
    "    transvar_cmd_p = \"/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i '{hgvs}' --refversion hg19\"\n",
    "    fn = 'parsed_abstracts_transvar.json'\n",
    "    f = open(fn, 'w')\n",
    "    counter = 0\n",
    "    input_transvar_fn = 'genes_hgvs.txt'\n",
    "    input_transvar_f = open(input_transvar_fn, 'w')\n",
    "    for parsed in load_parsed_abstracts():\n",
    "        counter += 1\n",
    "        \n",
    "        if counter < 0:\n",
    "            continue\n",
    "            \n",
    "        #if counter > 100:\n",
    "        #    break\n",
    "        \n",
    "        print 'Counter:', counter\n",
    "        \n",
    "        abstract = parsed['abstract']\n",
    "        \n",
    "        if 'dog' in abstract:\n",
    "            stats_2['nothumnan'] = stats_2.get('nothumnan', 0) + 1\n",
    "            continue\n",
    "\n",
    "        \n",
    "        #print parsed\n",
    "        hgvs = parsed['hgvs']\n",
    "        \n",
    "        #Get hgvs reference\n",
    "        s = re.search(r'([ACGT]+)>', hgvs)\n",
    "        if not s:\n",
    "            continue\n",
    "            #assert False\n",
    "            \n",
    "        hgvs_reference = s.group(1)\n",
    "                \n",
    "        #If it starts with a number assuming coding position\n",
    "        if re.search(r'^[\\d]+', hgvs, re.UNICODE):\n",
    "            hgvs = 'c.' + hgvs\n",
    "            \n",
    "            \n",
    "        #Get everything except the reference\n",
    "        s = re.search(r'^([^ACGT]+)[ACGT]+>', hgvs)\n",
    "        if not s:\n",
    "            continue\n",
    "            #assert False\n",
    "        except_reference = s.group(1)\n",
    "\n",
    "        \n",
    "        gene = parsed['gene']\n",
    "        if not gene:\n",
    "            continue\n",
    "            #assert False\n",
    "\n",
    "        transcripts = parsed['transcripts']\n",
    "        if transcripts:\n",
    "            pass\n",
    "            #assert False\n",
    "        \n",
    "        hgvs = gene + ':' + hgvs\n",
    "        hgvs_no_reference = gene + ':' + except_reference\n",
    "        #transvar_cmd = transvar_cmd_p.format(hgvs=hgvs)\n",
    "        transvar_cmd = transvar_cmd_p.format(hgvs=hgvs_no_reference)\n",
    "        #print transvar_cmd\n",
    "        #print abstract\n",
    "        #transvar_output = execute(transvar_cmd) # DO NOT EXECUTE IT\n",
    "        input_transvar_f.write('{}\\t{}\\n'.format(gene, except_reference))\n",
    "        continue\n",
    "        \n",
    "        parsed['transvar'] = transvar_output\n",
    "        f.write(json.dumps(parsed) + '\\n')\n",
    "        continue\n",
    "        \n",
    "        #print transvar_output\n",
    "        #transvar_output_f = StringIO(transvar_output)\n",
    "        #df = pd.read_csv(transvar_output_f, sep='\\t')\n",
    "        #print df\n",
    "        \n",
    "        transvar_references = parse_transvar_output(transvar_output, transvar_cmd, hgvs, abstract)\n",
    "        if len(transvar_references) == 0:\n",
    "            assert False\n",
    "            \n",
    "        if len(transvar_references) == 1:\n",
    "            if transvar_references.values()[0] == hgvs_reference:\n",
    "                stats_2['transvarok'] = stats_2.get('transvarok', 0) + 1\n",
    "            else:                \n",
    "                print transvar_cmd\n",
    "                print 'HGVS:', hgvs\n",
    "                print 'transvar_reference:', transvar_references.values()[0], 'Hgvs_reference:', hgvs_reference\n",
    "                assert transvar_references.values()[0]\n",
    "                assert hgvs_reference\n",
    "                stats_2['1_reference_not_compatible'] = stats_2.get('1_reference_not_compatible', 0) + 1\n",
    "        else:\n",
    "            # Take all references\n",
    "            all_references = list(set(transvar_references.values()))\n",
    "            if len(all_references) == 1:\n",
    "                if all_references[0] == hgvs_reference:\n",
    "                    stats_2['1_reference_many_transcripts'] = stats_2.get('1_reference_many_transcripts', 0) + 1\n",
    "                else:\n",
    "                    assert False\n",
    "            else:\n",
    "                assert hgvs_reference # Not null\n",
    "                assert [x for x in transvar_references.values() if x] # Not empty\n",
    "                if hgvs_reference in all_references:\n",
    "                    stats_2['many_references_exists'] = stats_2.get('many_references_exists', 0) + 1\n",
    "                else:\n",
    "                    stats_2['many_references_NOT_exists'] = stats_2.get('many_references_NOT_exists', 0) + 1\n",
    "\n",
    "    f.close()\n",
    "    input_transvar_f.close()\n",
    "    print 'Created_file:', input_transvar_fn\n",
    "    with open('stats_2.json', 'w') as f:\n",
    "        json.dump(stats_2, f)\n",
    "    \n",
    "    print 'created file:', fn\n",
    "    print 'Created file: stats_2.json'\n",
    "\n",
    "def do_3():\n",
    "    apply_transvar()\n",
    "    \n",
    "do_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN:\n",
    "\n",
    "```\n",
    "/home/user/mutationinfo/localpython/bin/transvar canno --ccds -l genes_hgvs.txt -g 1 -m 2 --refversion hg19 --oneline > transvar_output.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\ttranscript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\r\n",
      "RHAG:c.236G>A\tCCDS4927 (protein_coding)\tRHAG\t-\tchr6:g.49586997C>T/c.236G>A/p.S79N\tinside_[cds_in_exon_2]\tCSQN=Missense;reference_codon=AGT;alternative_codon=AAT;source=CCDS\r\n"
     ]
    }
   ],
   "source": [
    "!/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i 'RHAG:c.236G>A' --refversion hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\ttranscript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\n",
      "EXT2:c.969C>A\t.\t.\t.\t././.\t.\tno_valid_transcript_found\n"
     ]
    }
   ],
   "source": [
    "!/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i 'EXT2:c.969C>A' --refversion hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\ttranscript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\n",
      "EGFR:c.2576T>G\t.\t.\t.\t././.\t.\tno_valid_transcript_found\n"
     ]
    }
   ],
   "source": [
    "!/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i 'EGFR:c.2576T>G' --refversion hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\ttranscript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\n",
      "EGFR:c.2576\tCCDS5514 (protein_coding)\tEGFR\t+\tchr7:g.55259518C/c.2576C/.\tinside_[cds_in_exon_21]\tsource=CCDS\n"
     ]
    }
   ],
   "source": [
    "!/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i 'EGFR:c.2576' --refversion hg19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 cases of exon 21 2576T>G mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\ttranscript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\n",
      "EGFR:c.2576\tCCDS5514 (protein_coding)\tEGFR\t+\tchr7:g.55259518C/c.2576C/.\tinside_[cds_in_exon_21]\tsource=CCDS\n"
     ]
    }
   ],
   "source": [
    "!/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i 'EGFR:c.2576' --refversion hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\ttranscript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\n",
      "BRCA1:c.5251\tCCDS11453 (protein_coding)\tBRCA1\t-\tchr17:g.41209095G/c.5251C/.\tinside_[cds_in_exon_18]\tsource=CCDS\n",
      "BRCA1:c.5251\tCCDS11456 (protein_coding)\tBRCA1\t-\tchr17:g.41215355T/c.5251A/.\tinside_[cds_in_exon_18]\tsource=CCDS\n",
      "BRCA1:c.5251\tCCDS11459 (protein_coding)\tBRCA1\t-\tchr17:g.41201152A/c.5251T/.\tinside_[cds_in_exon_18]\tsource=CCDS\n"
     ]
    }
   ],
   "source": [
    "!/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i 'BRCA1:c.5251' --refversion hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\ttranscript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\n",
      "BRCA1:c.5251C>T\tCCDS11453 (protein_coding)\tBRCA1\t-\tchr17:g.41209095G>A/c.5251C>T/p.R1751*\tinside_[cds_in_exon_18]\tCSQN=Nonsense;reference_codon=CGA;alternative_codon=TGA;source=CCDS\n"
     ]
    }
   ],
   "source": [
    "!/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i 'BRCA1:c.5251C>T' --refversion hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\ttranscript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\n",
      "BRCA1:c.5251A>T\tCCDS11456 (protein_coding)\tBRCA1\t-\tchr17:g.41215355T>A/c.5251A>T/p.N1751Y\tinside_[cds_in_exon_18]\tCSQN=Missense;reference_codon=AAT;alternative_codon=TAT;source=CCDS\n"
     ]
    }
   ],
   "source": [
    "!/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i 'BRCA1:c.5251A>T' --refversion hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\ttranscript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\r\n",
      "IGSF1:c.2066\tCCDS14629 (protein_coding)\tIGSF1\t-\tchrX:g.130412084G/c.2066C/.\tinside_[cds_in_exon_12]\tsource=CCDS\r\n",
      "IGSF1:c.2066\tCCDS55490 (protein_coding)\tIGSF1\t-\tchrX:g.130412057T/c.2066A/.\tinside_[cds_in_exon_11]\tsource=CCDS\r\n",
      "IGSF1:c.2066\tCCDS55491 (protein_coding)\tIGSF1\t-\tchrX:g.130412099G/c.2066C/.\tinside_[cds_in_exon_12]\tsource=CCDS\r\n"
     ]
    }
   ],
   "source": [
    "!/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i 'IGSF1:c.2066' --refversion hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\ttranscript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\n",
      "IGSF1:c.2065+1G>A\t.\t.\t.\t././.\t.\tno_valid_transcript_found\n"
     ]
    }
   ],
   "source": [
    "!/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i 'IGSF1:c.2065+1G>A' --refversion hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\ttranscript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\r\n",
      "FAH:c.1062+5\tCCDS10314 (protein_coding)\tFAH\t+\tchr15:g.80472572G/c.1062+5G/.\tinside_[intron_between_exon_12_and_13]\tsource=CCDS\r\n"
     ]
    }
   ],
   "source": [
    "!/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i 'FAH:c.1062+5' --refversion hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\ttranscript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\n",
      "[wrap_exception] warning: invalid_gene_PCD\n",
      "PCD:c.710\t.\t.\t.\t././.\t.\tError_invalid_gene_PCD\n"
     ]
    }
   ],
   "source": [
    "!/home/user/mutationinfo/localpython/bin/transvar canno --ccds -i 'PCD:c.710' --refversion hg19 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 3\n",
    "Run with ```/home/user/mutationinfo/localpython/bin/python run_3.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run_3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_3.py\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "def load_parsed_abstracts():\n",
    "    with open('parsed_abstracts.json') as f:\n",
    "        for l in f:\n",
    "            data = json.loads(l)\n",
    "            yield data\n",
    "            \n",
    "def hgvs_from_record(parsed):\n",
    "        \n",
    "    abstract = parsed['abstract']\n",
    "\n",
    "    if 'dog' in abstract:\n",
    "        #stats_2['nothumnan'] = stats_2.get('nothumnan', 0) + 1\n",
    "        return None\n",
    "\n",
    "\n",
    "    #print parsed\n",
    "    hgvs = parsed['hgvs']\n",
    "\n",
    "    #Get hgvs reference\n",
    "    s = re.search(r'([ACGT]+)>', hgvs)\n",
    "    if not s:\n",
    "        return None\n",
    "        #assert False\n",
    "\n",
    "    hgvs_reference = s.group(1)\n",
    "\n",
    "    #If it starts with a number assuming coding position\n",
    "    if re.search(r'^[\\d]+', hgvs, re.UNICODE):\n",
    "        hgvs = 'c.' + hgvs\n",
    "\n",
    "\n",
    "    #Get everything except the reference\n",
    "    s = re.search(r'^([^ACGT]+)[ACGT]+>', hgvs)\n",
    "    if not s:\n",
    "        return None\n",
    "        #continue\n",
    "        #assert False\n",
    "    except_reference = s.group(1)\n",
    "\n",
    "\n",
    "    gene = parsed['gene']\n",
    "    if not gene:\n",
    "        return None\n",
    "        #assert False\n",
    "\n",
    "    transcripts = parsed['transcripts']\n",
    "    if transcripts:\n",
    "        pass\n",
    "        #assert False\n",
    "\n",
    "    hgvs = gene + ':' + hgvs\n",
    "    hgvs_no_reference = gene + ':' + except_reference\n",
    "    #transvar_cmd = transvar_cmd_p.format(hgvs=hgvs)\n",
    "    return hgvs\n",
    "\n",
    "def vep_parse(hgvs):\n",
    "    headers={ \"Content-Type\" : \"application/json\"}\n",
    "    vep_url = \"https://rest.ensembl.org/vep/human/hgvs/{var}?\"\n",
    "\n",
    "    url = vep_url.format(var=hgvs)\n",
    "    responce = requests.get(url, headers=headers)\n",
    "    if responce.ok:\n",
    "        return responce.json()\n",
    "    else:\n",
    "        print ('Error:')\n",
    "        print (responce.text)\n",
    "\n",
    "def vep_parse_post(hgvs):\n",
    "\n",
    " \n",
    "    server = \"https://rest.ensembl.org\"\n",
    "    ext = \"/vep/human/hgvs\"\n",
    "    headers={ \"Content-Type\" : \"application/json\", \"Accept\" : \"application/json\"}\n",
    "    \n",
    "    assert type(hgvs) is list\n",
    "    #data = '[' + ','.join([rept(x) for x in hgvs]) + ']'\n",
    "    data = json.dumps({\"hgvs_notations\": hgvs})\n",
    "    print data\n",
    "    \n",
    "    r = requests.post(server+ext, headers=headers, data=data)\n",
    " \n",
    "    if not r.ok:\n",
    "        print ('ERROR:')\n",
    "        print (r.text)\n",
    "        return None\n",
    " \n",
    "    decoded = r.json()\n",
    "    return decoded\n",
    "\n",
    "def vep_run():\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    f = open('vep_results.json', 'w')\n",
    "    \n",
    "    all_hgvs = set()\n",
    "    for parsed in load_parsed_abstracts():\n",
    "        count += 1\n",
    "        \n",
    "        print ('count:', count)\n",
    "        \n",
    "        if count < 1:\n",
    "            continue\n",
    "            \n",
    "        #if count > 10:\n",
    "        #    break\n",
    "        \n",
    "        hgvs = hgvs_from_record(parsed)\n",
    "        print hgvs\n",
    "        \n",
    "        if hgvs is None:\n",
    "            continue\n",
    "        \n",
    "        all_hgvs.add(hgvs)\n",
    "        if len(all_hgvs) <200:\n",
    "            continue\n",
    "        \n",
    "        # Accessing VEP!\n",
    "        vep = vep_parse_post(list(all_hgvs))\n",
    "        \n",
    "        # Saving\n",
    "        f.write(json.dumps(vep) + '\\n')\n",
    "        \n",
    "        #Emptying set\n",
    "        all_hgvs = set()\n",
    "        time.sleep(10) # Be nice\n",
    "        \n",
    "        #vep = vep_parse(hgvs)\n",
    "        #vep = vep_parse_post([hgvs])\n",
    "        #print vep\n",
    "        #assert False\n",
    "\n",
    "    # Last batch\n",
    "    vep = vep_parse_post(list(all_hgvs))    \n",
    "    f.write(json.dumps(vep) + '\\n')\n",
    "\n",
    "        \n",
    "    f.close()\n",
    "    print ('Created: vep_results.json')\n",
    "        \n",
    "vep_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mutationinfo/localpython/lib/python2.7/site-packages/psycopg2-2.7.4-py2.7-linux-x86_64.egg/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import hgvs.parser\n",
    "import hgvs.dataproviders.uta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp = hgvs.dataproviders.uta.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgvs_parser = hgvs.parser.Parser().parse_hgvs_variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " p = hgvs_parser('RHAG:c.236G>A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hgvs.variantmapper\n",
    "import hgvs.assemblymapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = hgvs.assemblymapper.AssemblyMapper(hdp, alt_aln_method=u'genewise',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "HGVSDataNotAvailableError",
     "evalue": "No alignments for RHAG in GRCh38 using genewise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHGVSDataNotAvailableError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6f5829b3df9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_to_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/user/mutationinfo/localpython/lib/python2.7/site-packages/hgvs-1.1.1-py2.7.egg/hgvs/assemblymapper.pyc\u001b[0m in \u001b[0;36mc_to_g\u001b[0;34m(self, var_c)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mc_to_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0malt_ac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alt_ac_for_tx_ac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mvar_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAssemblyMapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_to_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt_ac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt_aln_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malt_aln_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/mutationinfo/localpython/lib/python2.7/site-packages/hgvs-1.1.1-py2.7.egg/hgvs/assemblymapper.pyc\u001b[0m in \u001b[0;36m_alt_ac_for_tx_ac\u001b[0;34m(self, tx_ac)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malt_acs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             raise HGVSDataNotAvailableError(\"No alignments for {tx_ac} in {an} using {am}\".format(\n\u001b[0;32m--> 140\u001b[0;31m                 tx_ac=tx_ac, an=self.assembly_name, am=self.alt_aln_method))\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malt_acs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHGVSDataNotAvailableError\u001b[0m: No alignments for RHAG in GRCh38 using genewise"
     ]
    }
   ],
   "source": [
    "am.c_to_g(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'variantmapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ce4f3ed11a66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvariantmapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'variantmapper' is not defined"
     ]
    }
   ],
   "source": [
    "variantmapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VEP but for hg19\n",
    "Run with ```/home/user/mutationinfo/localpython/bin/python run_4.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run_4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_4.py\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "def load_parsed_abstracts():\n",
    "    with open('parsed_abstracts.json') as f:\n",
    "        for l in f:\n",
    "            data = json.loads(l)\n",
    "            yield data\n",
    "            \n",
    "def hgvs_from_record(parsed):\n",
    "        \n",
    "    abstract = parsed['abstract']\n",
    "\n",
    "    if 'dog' in abstract:\n",
    "        #stats_2['nothumnan'] = stats_2.get('nothumnan', 0) + 1\n",
    "        return None\n",
    "\n",
    "\n",
    "    #print parsed\n",
    "    hgvs = parsed['hgvs']\n",
    "\n",
    "    #Get hgvs reference\n",
    "    s = re.search(r'([ACGT]+)>', hgvs)\n",
    "    if not s:\n",
    "        return None\n",
    "        #assert False\n",
    "\n",
    "    hgvs_reference = s.group(1)\n",
    "\n",
    "    #If it starts with a number assuming coding position\n",
    "    if re.search(r'^[\\d]+', hgvs, re.UNICODE):\n",
    "        hgvs = 'c.' + hgvs\n",
    "\n",
    "\n",
    "    #Get everything except the reference\n",
    "    s = re.search(r'^([^ACGT]+)[ACGT]+>', hgvs)\n",
    "    if not s:\n",
    "        return None\n",
    "        #continue\n",
    "        #assert False\n",
    "    except_reference = s.group(1)\n",
    "\n",
    "\n",
    "    gene = parsed['gene']\n",
    "    if not gene:\n",
    "        return None\n",
    "        #assert False\n",
    "\n",
    "    transcripts = parsed['transcripts']\n",
    "    if transcripts:\n",
    "        pass\n",
    "        #assert False\n",
    "\n",
    "    hgvs = gene + ':' + hgvs\n",
    "    hgvs_no_reference = gene + ':' + except_reference\n",
    "    #transvar_cmd = transvar_cmd_p.format(hgvs=hgvs)\n",
    "    return hgvs\n",
    "\n",
    "def vep_parse(hgvs):\n",
    "    headers={ \"Content-Type\" : \"application/json\"}\n",
    "    vep_url = \"https://grch37.rest.ensembl.org/vep/human/hgvs/{var}?\"\n",
    "\n",
    "    url = vep_url.format(var=hgvs)\n",
    "    responce = requests.get(url, headers=headers)\n",
    "    if responce.ok:\n",
    "        return responce.json()\n",
    "    else:\n",
    "        print ('Error:')\n",
    "        print (responce.text)\n",
    "\n",
    "def vep_parse_post(hgvs):\n",
    "\n",
    " \n",
    "    server = \"https://grch37.rest.ensembl.org\"\n",
    "    ext = \"/vep/human/hgvs\"\n",
    "    headers={ \"Content-Type\" : \"application/json\", \"Accept\" : \"application/json\"}\n",
    "    \n",
    "    assert type(hgvs) is list\n",
    "    #data = '[' + ','.join([rept(x) for x in hgvs]) + ']'\n",
    "    data = json.dumps({\"hgvs_notations\": hgvs})\n",
    "    print data\n",
    "    \n",
    "    r = requests.post(server+ext, headers=headers, data=data)\n",
    " \n",
    "    if not r.ok:\n",
    "        print ('ERROR:')\n",
    "        print (r.text)\n",
    "        return None\n",
    " \n",
    "    decoded = r.json()\n",
    "    return decoded\n",
    "\n",
    "def vep_run():\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    f = open('vep_results_hg19.json', 'w')\n",
    "    \n",
    "    all_hgvs = set()\n",
    "    for parsed in load_parsed_abstracts():\n",
    "        count += 1\n",
    "        \n",
    "        print ('count:', count)\n",
    "        \n",
    "        if count < 1:\n",
    "            continue\n",
    "            \n",
    "        #if count > 10:\n",
    "        #    break\n",
    "        \n",
    "        hgvs = hgvs_from_record(parsed)\n",
    "        print hgvs\n",
    "        \n",
    "        if hgvs is None:\n",
    "            continue\n",
    "        \n",
    "        all_hgvs.add(hgvs)\n",
    "        if len(all_hgvs) <200:\n",
    "            continue\n",
    "        \n",
    "        # Accessing VEP!\n",
    "        vep = vep_parse_post(list(all_hgvs))\n",
    "        \n",
    "        #print vep\n",
    "        #assert False\n",
    "        \n",
    "        # Saving\n",
    "        f.write(json.dumps(vep) + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        #Emptying set\n",
    "        all_hgvs = set()\n",
    "        time.sleep(10) # Be nice\n",
    "        \n",
    "        #vep = vep_parse(hgvs)\n",
    "        #vep = vep_parse_post([hgvs])\n",
    "        #print vep\n",
    "        #assert False\n",
    "\n",
    "    # Last batch\n",
    "    vep = vep_parse_post(list(all_hgvs))    \n",
    "    f.write(json.dumps(vep) + '\\n')\n",
    "\n",
    "        \n",
    "    f.close()\n",
    "    print ('Created: vep_results_hg19.json')\n",
    "        \n",
    "vep_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 154\n",
      "Record: 13143\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def vep_info(vep):\n",
    "    # Take only the essential info\n",
    "    ret = {\n",
    "        'chr': vep['seq_region_name'],\n",
    "        'start' : vep['start'],\n",
    "        'end' : vep['end'],\n",
    "        'allele_string' : vep['allele_string'].split('/'),\n",
    "        'strand' : vep['strand'],\n",
    "    }\n",
    "   \n",
    "    return ret\n",
    "\n",
    "def load_vep_results(fn):    \n",
    "    ret = {}\n",
    "    \n",
    "    with open(fn) as f:\n",
    "        c = 0\n",
    "        for l in f:\n",
    "            c += 1\n",
    "            data = json.loads(l)\n",
    "\n",
    "            #print data[0]\n",
    "            #assert False\n",
    "            \n",
    "            for variant in data:\n",
    "                ret[variant['id']] = vep_info(variant)\n",
    "            \n",
    "    print 'Lines:', c\n",
    "    print 'Record:', len(ret)\n",
    "    return ret\n",
    "\n",
    "#vep = load_vep_results('vep_results.json') # Replace this with 'vep_results_hg19.json'\n",
    "vep = load_vep_results('vep_results_hg19.json') # Replace this with 'vep_results_hg19.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transvar_results(fn):\n",
    "    '''\n",
    "    transvar_output.txt\n",
    "    '''\n",
    "\n",
    "    ret = {}\n",
    "    with open(fn) as f:\n",
    "        c=0\n",
    "        for l in f:\n",
    "            c+=1\n",
    "            ls = l.replace('\\n', '').split('\\t')\n",
    "            if c == 1:\n",
    "                header = ls\n",
    "                header_str = l\n",
    "                continue\n",
    "                \n",
    "            ret[ls[0]] = '\\t'.join(header[1:]) + '\\n' + '\\t'.join(ls[1:]).replace('|||', '\\n')\n",
    "            break\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=load_transvar_results('transvar_output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RHAG|c.236']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcript\tgene\tstrand\tcoordinates(gDNA/cDNA/protein)\tregion\tinfo\n",
      "CCDS4927 (protein_coding)\tRHAG\t-\tchr6:g.49586997C/c.236G/.\tinside_[cds_in_exon_2]\tsource=CCDS\n"
     ]
    }
   ],
   "source": [
    "print a['RHAG|c.236']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records: 10000\n",
      "Records: 20000\n",
      "Records: 30000\n",
      "Records: 40000\n",
      "{\n",
      "    \"transvar_found ././.\": 14614, \n",
      "    \"YES_VEP\": 19604, \n",
      "    \"reference_found_only\": 16845, \n",
      "    \"reference_found\": 20245, \n",
      "    \"reference_not_found\": 5991, \n",
      "    \"vep_concordant\": 18763, \n",
      "    \"not_reference_found_only\": 5991, \n",
      "    \"NO_VEP\": 21246, \n",
      "    \"NO_VEP_NO_TR\": 13973, \n",
      "    \"YES_VEP_YES_TR\": 26236, \n",
      "    \"vep_discordant\": 3194, \n",
      "    \"hgvs_reference_SAME_VEP\": 18963, \n",
      "    \"reference_found_and_reference_not_found\": 3400, \n",
      "    \"not_vep_concordant_not_discordant\": 7273, \n",
      "    \"transvar_found_something\": 26236, \n",
      "    \"more_than_one\": 8619, \n",
      "    \"not_vep_concordant_and_discordant\": 200, \n",
      "    \"vep_concordant_and_not_discordant\": 15769, \n",
      "    \"YES_TR\": 26236, \n",
      "    \"YES_VEP_NO_TR\": 14614, \n",
      "    \"ALL_PERFECT\": 15769, \n",
      "    \"NO_VEP_YES_TR\": 7273, \n",
      "    \"transvar_crashed\": 3, \n",
      "    \"vep_concordant_and_discordant\": 2994\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def hgvs_from_record(parsed):\n",
    "        \n",
    "    abstract = parsed['abstract']\n",
    "\n",
    "    if 'dog' in abstract:\n",
    "        #stats_2['nothumnan'] = stats_2.get('nothumnan', 0) + 1\n",
    "        return None\n",
    "\n",
    "\n",
    "    #print parsed\n",
    "    hgvs = parsed['hgvs']\n",
    "\n",
    "    #Get hgvs reference\n",
    "    s = re.search(r'([ACGT]+)>', hgvs)\n",
    "    if not s:\n",
    "        return None\n",
    "        #assert False\n",
    "\n",
    "    hgvs_reference = s.group(1)\n",
    "\n",
    "    #If it starts with a number assuming coding position\n",
    "    if re.search(r'^[\\d]+', hgvs, re.UNICODE):\n",
    "        hgvs = 'c.' + hgvs\n",
    "\n",
    "\n",
    "    #Get everything except the reference\n",
    "    s = re.search(r'^([^ACGT]+)[ACGT]+>', hgvs)\n",
    "    if not s:\n",
    "        return None\n",
    "        #continue\n",
    "        #assert False\n",
    "    except_reference = s.group(1)\n",
    "\n",
    "\n",
    "    gene = parsed['gene']\n",
    "    if not gene:\n",
    "        return None\n",
    "        #assert False\n",
    "\n",
    "    transcripts = parsed['transcripts']\n",
    "    if transcripts:\n",
    "        pass\n",
    "        #assert False\n",
    "\n",
    "    hgvs = gene + ':' + hgvs\n",
    "    hgvs_no_reference = gene + ':' + except_reference\n",
    "    transvar_key = gene + '|' + except_reference\n",
    "    #transvar_cmd = transvar_cmd_p.format(hgvs=hgvs)\n",
    "    return hgvs, hgvs_reference, transvar_key\n",
    "\n",
    "def inverse(s):\n",
    "    \n",
    "    return {\n",
    "        'A': 'T',\n",
    "        'T': 'A',\n",
    "        'C': 'G',\n",
    "        'G': 'C',\n",
    "    }[s]\n",
    "\n",
    "def get_transvar_reference(coord, strand):\n",
    "    s = re.search(r'chr[\\dXY]+:g.[\\d]+([ACGT]+)/', coord)\n",
    "    if s:\n",
    "        reference = s.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    if strand == '-':\n",
    "        return inverse(reference)\n",
    "    elif strand == '+':\n",
    "        return reference\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "def get_transvar_chromosome_position(coord):\n",
    "    s = re.search(r'chr([\\dXY]+):g.([\\d]+)', coord)\n",
    "    if s:\n",
    "        return s.group(1), int(s.group(2))\n",
    "\n",
    "    if coord == '././.':\n",
    "        return None, None\n",
    "    \n",
    "    print (coord)\n",
    "    assert False\n",
    "        \n",
    "    \n",
    "    \n",
    "def parse_transvar_output(output):\n",
    "    ls = output.split('\\n')\n",
    "    ls = [x.split('\\t') for x in ls if x.strip()]\n",
    "    try:\n",
    "        strand_i = ls[0].index('strand')\n",
    "    except Exception as e:\n",
    "        print '====='\n",
    "        print output\n",
    "        print '====='\n",
    "        raise e\n",
    "    coord_i = ls[0].index('coordinates(gDNA/cDNA/protein)')\n",
    "    transcript_i = ls[0].index('transcript')\n",
    "    \n",
    "    ret = {l[transcript_i]:{\n",
    "        'reference': get_transvar_reference(l[coord_i], l[strand_i]),\n",
    "        'position': get_transvar_chromosome_position(l[coord_i]),\n",
    "        } for l in ls[1:]}\n",
    "    return ret    \n",
    "\n",
    "def add_one(d, key):\n",
    "    d[key] = d.get(key, 0) + 1\n",
    "\n",
    "def load_transvar_results(fn):\n",
    "    \n",
    "    stats_3 = {}\n",
    "    \n",
    "    c = 0\n",
    "    with open(fn) as f:\n",
    "        for l in f:\n",
    "            c += 1\n",
    "            \n",
    "            if c % 10000 == 0:\n",
    "                print 'Records:', c\n",
    "            \n",
    "            data = json.loads(l)\n",
    "            \n",
    "            hgvs, hgvs_reference, transvar_key = hgvs_from_record(data)\n",
    "            #print hgvs\n",
    "            #print hgvs_reference\n",
    "            transvar_output = data['transvar'] # THERE IS NOT DATA THERE! FIX IT\n",
    "            #print transvar_output\n",
    "            if not transvar_output.strip():\n",
    "                add_one(stats_3, 'transvar_crashed')\n",
    "                continue\n",
    "            \n",
    "            transvar_info = parse_transvar_output(transvar_output)\n",
    "            #print transvar_info                \n",
    "            vep_info = vep.get(hgvs, None)\n",
    "            #print vep_info\n",
    "            \n",
    "            \n",
    "            NO_VEP = False\n",
    "            YES_YEP = False\n",
    "            NO_TR = False\n",
    "            YES_TR = False\n",
    "            \n",
    "            if vep_info is None:\n",
    "                NO_VEP = True\n",
    "                add_one(stats_3, 'NO_VEP')\n",
    "            else:\n",
    "                YES_VEP = True\n",
    "                add_one(stats_3, 'YES_VEP')\n",
    "            \n",
    "            if all([x['position'][1] is None for x in transvar_info.values()]):\n",
    "                    add_one(stats_3, 'transvar_found ././.')\n",
    "                    # TODO: CHECK VEP HGVS_REF!!!\n",
    "                    NO_TR = True\n",
    "            else:\n",
    "                YES_TR = True\n",
    "                add_one(stats_3, 'YES_TR')\n",
    "            \n",
    "            for x in [('YES_VEP', YES_VEP), ('NO_VEP', NO_VEP)]:\n",
    "                for y in [('YES_TR', YES_TR), ('NO_TR', NO_TR)]:\n",
    "                    if x[1] and y[1]:\n",
    "                        add_one(stats_3, x[0] + '_' + y[0])\n",
    "            \n",
    "            #if YES_VEP and NO_TR:\n",
    "            #    print data\n",
    "            #    print '====='\n",
    "            #    print vep_info\n",
    "            #    #assert False\n",
    "            \n",
    "            if NO_TR:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            more_than_one = False\n",
    "            reference_found = False\n",
    "            reference_not_found = False\n",
    "            more_than_one_marked = False\n",
    "            vep_concordant = False\n",
    "            vep_discordant = False\n",
    "            for k,v in transvar_info.iteritems():\n",
    "                if more_than_one:\n",
    "                    if not more_than_one_marked:\n",
    "                        add_one(stats_3, 'more_than_one')\n",
    "                        more_than_one_marked = True\n",
    "                \n",
    "                if v['reference'] == hgvs_reference:\n",
    "                    reference_found = True\n",
    "                    \n",
    "                if v['reference'] != hgvs_reference:\n",
    "                    reference_not_found = True\n",
    "                \n",
    "                if vep_info:\n",
    "                    if v['reference'] in vep_info['allele_string']:\n",
    "                        if vep_info['allele_string'].index(v['reference']) == 0:\n",
    "                            if vep_info['start'] == v['position'][1]:\n",
    "                                vep_concordant = True\n",
    "                            else:\n",
    "                                vep_discordant = True\n",
    "                        else:\n",
    "                            vep_discordant = True\n",
    "                    else:\n",
    "                        vep_discordant = True\n",
    "                \n",
    "                more_than_one = True\n",
    "            \n",
    "            if not more_than_one:\n",
    "                # Transvar found nada\n",
    "                add_one(stats_3, 'transvar_not_found')\n",
    "            else:\n",
    "                add_one(stats_3, 'transvar_found_something')\n",
    "            \n",
    "            if reference_found:\n",
    "                add_one(stats_3, 'reference_found')\n",
    "            else:\n",
    "                add_one(stats_3, 'reference_not_found')\n",
    "                \n",
    "            if reference_found and reference_not_found: # I know..\n",
    "                add_one(stats_3, 'reference_found_and_reference_not_found')\n",
    "                \n",
    "            if reference_found and not reference_not_found:\n",
    "                add_one(stats_3, 'reference_found_only')\n",
    "                \n",
    "            if not reference_found and reference_not_found:\n",
    "                add_one(stats_3, 'not_reference_found_only')\n",
    "                \n",
    "            if not reference_found and not reference_not_found:\n",
    "                assert False\n",
    "            \n",
    "            if vep_concordant:\n",
    "                add_one(stats_3, 'vep_concordant')\n",
    "            \n",
    "            if vep_discordant:\n",
    "                add_one(stats_3, 'vep_discordant')\n",
    "            \n",
    "            if vep_concordant and vep_discordant: # Can happen\n",
    "                add_one(stats_3, 'vep_concordant_and_discordant')\n",
    "                \n",
    "            if vep_concordant and not vep_discordant:\n",
    "                add_one(stats_3, 'vep_concordant_and_not_discordant')\n",
    "                \n",
    "            if not vep_concordant and vep_discordant:\n",
    "                add_one(stats_3, 'not_vep_concordant_and_discordant')\n",
    "                \n",
    "            if not vep_concordant and not vep_discordant:\n",
    "                add_one(stats_3, 'not_vep_concordant_not_discordant')\n",
    "\n",
    "            hgvs_vep_concordance = False\n",
    "            if vep_info:\n",
    "                if hgvs_reference in vep_info['allele_string']:\n",
    "                    if vep_info['allele_string'].index(hgvs_reference) == 0:\n",
    "                        add_one(stats_3, 'hgvs_reference_SAME_VEP')\n",
    "                        hgvs_vep_concordance = True\n",
    "                    else:\n",
    "                        add_one(stats_3, 'hgvs_reference_NOT_SAME_VEP')\n",
    "                else:\n",
    "                    add_one(stats_3, 'hgvs_reference_NOT_PRESENT_IN_VEP')\n",
    "                    \n",
    "            if hgvs_vep_concordance and reference_found and not reference_not_found and vep_concordant and not vep_discordant:\n",
    "                add_one(stats_3, 'ALL_PERFECT')\n",
    "            \n",
    "            #print (stats_3)\n",
    "            #assert False\n",
    "            \n",
    "    print (json.dumps(stats_3, indent=4))\n",
    "\n",
    "load_transvar_results('parsed_abstracts_transvar.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26234"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40850-14616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgvs = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
